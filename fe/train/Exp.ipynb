{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a1961b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset xlsum (C:\\Users\\assam\\.cache\\huggingface\\datasets\\csebuetnlp___xlsum\\indonesian\\2.0.0\\518ab0af76048660bcc2240ca6e8692a977c80e384ffb18fdddebaca6daebdce)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90ddf137bf243c982713a623a502f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csebuetnlp/xlsum\", 'indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bd6cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d422887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141105_seni_vangogh</td>\n",
       "      <td>https://www.bbc.com/indonesia/majalah/2014/11/...</td>\n",
       "      <td>Lukisan bunga Van Gogh terjual US$61,8 juta</td>\n",
       "      <td>Sebuah mahakarya Vincent van Gogh, yang diluki...</td>\n",
       "      <td>Still Life, Vase with Daisies, and Poppies dib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dunia-49410599</td>\n",
       "      <td>https://www.bbc.com/indonesia/dunia-49410599</td>\n",
       "      <td>Mengapa pengungsi Suriah diminta segera mening...</td>\n",
       "      <td>Ribuan pengungsi Suriah punya waktu hingga Sel...</td>\n",
       "      <td>Foto tanggal 6 Agustus ini memperlihatkan kelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trensosial-38156839</td>\n",
       "      <td>https://www.bbc.com/indonesia/trensosial-38156839</td>\n",
       "      <td>Para pemain Chapecoense akan dikenang selamany...</td>\n",
       "      <td>Ribuan orang berkumpul di kota Chapeco, Brasil...</td>\n",
       "      <td>Para keluarga korban berada di tengah fan yang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160317_dunia_turki_kurdi_serangan</td>\n",
       "      <td>https://www.bbc.com/indonesia/dunia/2016/03/16...</td>\n",
       "      <td>Kelompok Kurdi TAK klaim mengebom Ankara</td>\n",
       "      <td>Kelompok militan Kurdi TAK mengatakan pihaknya...</td>\n",
       "      <td>Disebutkan oleh TAK bahwa korban sipil tak bis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dunia-52171474</td>\n",
       "      <td>https://www.bbc.com/indonesia/dunia-52171474</td>\n",
       "      <td>Virus corona: Sejumlah dokter di India ‘diluda...</td>\n",
       "      <td>Sejumlah tenaga kesehatan di India dilaporkan ...</td>\n",
       "      <td>Para dokter di India bekerja lembur untuk meng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0                141105_seni_vangogh   \n",
       "1                     dunia-49410599   \n",
       "2                trensosial-38156839   \n",
       "3  160317_dunia_turki_kurdi_serangan   \n",
       "4                     dunia-52171474   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.bbc.com/indonesia/majalah/2014/11/...   \n",
       "1       https://www.bbc.com/indonesia/dunia-49410599   \n",
       "2  https://www.bbc.com/indonesia/trensosial-38156839   \n",
       "3  https://www.bbc.com/indonesia/dunia/2016/03/16...   \n",
       "4       https://www.bbc.com/indonesia/dunia-52171474   \n",
       "\n",
       "                                               title  \\\n",
       "0        Lukisan bunga Van Gogh terjual US$61,8 juta   \n",
       "1  Mengapa pengungsi Suriah diminta segera mening...   \n",
       "2  Para pemain Chapecoense akan dikenang selamany...   \n",
       "3           Kelompok Kurdi TAK klaim mengebom Ankara   \n",
       "4  Virus corona: Sejumlah dokter di India ‘diluda...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Sebuah mahakarya Vincent van Gogh, yang diluki...   \n",
       "1  Ribuan pengungsi Suriah punya waktu hingga Sel...   \n",
       "2  Ribuan orang berkumpul di kota Chapeco, Brasil...   \n",
       "3  Kelompok militan Kurdi TAK mengatakan pihaknya...   \n",
       "4  Sejumlah tenaga kesehatan di India dilaporkan ...   \n",
       "\n",
       "                                                text  \n",
       "0  Still Life, Vase with Daisies, and Poppies dib...  \n",
       "1  Foto tanggal 6 Agustus ini memperlihatkan kelu...  \n",
       "2  Para keluarga korban berada di tengah fan yang...  \n",
       "3  Disebutkan oleh TAK bahwa korban sipil tak bis...  \n",
       "4  Para dokter di India bekerja lembur untuk meng...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f4afef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sebuah mahakarya Vincent van Gogh, yang diluki...</td>\n",
       "      <td>Still Life, Vase with Daisies, and Poppies dib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ribuan pengungsi Suriah punya waktu hingga Sel...</td>\n",
       "      <td>Foto tanggal 6 Agustus ini memperlihatkan kelu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ribuan orang berkumpul di kota Chapeco, Brasil...</td>\n",
       "      <td>Para keluarga korban berada di tengah fan yang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kelompok militan Kurdi TAK mengatakan pihaknya...</td>\n",
       "      <td>Disebutkan oleh TAK bahwa korban sipil tak bis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sejumlah tenaga kesehatan di India dilaporkan ...</td>\n",
       "      <td>Para dokter di India bekerja lembur untuk meng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  Sebuah mahakarya Vincent van Gogh, yang diluki...   \n",
       "1  Ribuan pengungsi Suriah punya waktu hingga Sel...   \n",
       "2  Ribuan orang berkumpul di kota Chapeco, Brasil...   \n",
       "3  Kelompok militan Kurdi TAK mengatakan pihaknya...   \n",
       "4  Sejumlah tenaga kesehatan di India dilaporkan ...   \n",
       "\n",
       "                                                text  \n",
       "0  Still Life, Vase with Daisies, and Poppies dib...  \n",
       "1  Foto tanggal 6 Agustus ini memperlihatkan kelu...  \n",
       "2  Para keluarga korban berada di tengah fan yang...  \n",
       "3  Disebutkan oleh TAK bahwa korban sipil tak bis...  \n",
       "4  Para dokter di India bekerja lembur untuk meng...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['summary', 'text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78e9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Remove non-alphabetic characters (Data Cleaning)\n",
    "def text_strip(column):\n",
    "\n",
    "    for row in column:\n",
    "        row = re.sub(\"(\\\\t)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\\\r)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\\\n)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove _ if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(__+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove - if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(--+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove ~ if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(~~+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove + if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(\\+\\++)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove . if it occurs more than one time consecutively\n",
    "        row = re.sub(\"(\\.\\.+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove the characters - <>()|&©ø\"',;?~*!\n",
    "        row = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove mailto:\n",
    "        row = re.sub(\"(mailto:)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove \\x9* in text\n",
    "        row = re.sub(r\"(\\\\x9\\d)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Replace INC nums to INC_NUM\n",
    "        row = re.sub(\"([iI][nN][cC]\\d+)\", \"INC_NUM\", str(row)).lower()\n",
    "\n",
    "        # Replace CM# and CHG# to CM_NUM\n",
    "        row = re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", \"CM_NUM\", str(row)).lower()\n",
    "\n",
    "        # Remove punctuations at the end of a word\n",
    "        row = re.sub(\"(\\.\\s+)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\-\\s+)\", \" \", str(row)).lower()\n",
    "        row = re.sub(\"(\\:\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Replace any url to only the domain name\n",
    "        try:\n",
    "            url = re.search(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r\"((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)\", repl_url, str(row))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Remove multiple spaces\n",
    "        row = re.sub(\"(\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        # Remove the single character hanging between any two spaces\n",
    "        row = re.sub(\"(\\s+.\\s+)\", \" \", str(row)).lower()\n",
    "\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "420775c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = text_strip(df['text'])\n",
    "processed_summary = text_strip(df['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2d6c2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[1;32m----> 4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Process text as batches and yield Doc objects in order\u001b[39;00m\n\u001b[0;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipe(processed_text, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py:426\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models. If you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from time import time\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) \n",
    "\n",
    "# Process text as batches and yield Doc objects in order\n",
    "text = [str(doc) for doc in nlp.pipe(processed_text, batch_size=5000)]\n",
    "\n",
    "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(processed_summary, batch_size=5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16b97853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_START_ seekor gajah mendadak mengamuk saat prosesi tahunan agama buddha di kolombo sri lanka sehingga membuat peserta upacara tunggang-langgang setidaknya 17 orang terluka. _END_'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4d2fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = pd.Series(text)\n",
    "df['cleaned_summary'] = pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99048f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seekor gajah mendadak mengamuk saat prosesi ta...</td>\n",
       "      <td>Dilaporkan dua orang terluka cukup serius, sem...</td>\n",
       "      <td>dilaporkan dua orang terluka cukup serius seme...</td>\n",
       "      <td>_START_ seekor gajah mendadak mengamuk saat pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Presiden Jokowi memutuskan untuk menghapus 14 ...</td>\n",
       "      <td>Proyek MRT Sudirman- Lebak Bulus tengah dikerj...</td>\n",
       "      <td>proyek mrt sudirman lebak bulus tengah dikerja...</td>\n",
       "      <td>_START_ presiden jokowi memutuskan untuk mengh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  Seekor gajah mendadak mengamuk saat prosesi ta...   \n",
       "1  Presiden Jokowi memutuskan untuk menghapus 14 ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Dilaporkan dua orang terluka cukup serius, sem...   \n",
       "1  Proyek MRT Sudirman- Lebak Bulus tengah dikerj...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  dilaporkan dua orang terluka cukup serius seme...   \n",
       "1  proyek mrt sudirman lebak bulus tengah dikerja...   \n",
       "\n",
       "                                     cleaned_summary  \n",
       "0  _START_ seekor gajah mendadak mengamuk saat pr...  \n",
       "1  _START_ presiden jokowi memutuskan untuk mengh...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "861cb67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_count = []\n",
    "summary_count = []\n",
    "\n",
    "for sent in df['cleaned_text']:\n",
    "    text_count.append(len(sent.split()))\n",
    "    \n",
    "for sent in df['cleaned_summary']:\n",
    "    summary_count.append(len(sent.split()))\n",
    "\n",
    "graph_df = pd.DataFrame() \n",
    "\n",
    "graph_df['text'] = text_count\n",
    "graph_df['summary'] = summary_count\n",
    "\n",
    "graph_df.hist(bins = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8afe39ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9724909785053083\n"
     ]
    }
   ],
   "source": [
    "# Check how much % of text have 0-100 words\n",
    "cnt = 0\n",
    "for i in df['cleaned_text']:\n",
    "    if len(i.split()) <= 1500:\n",
    "        cnt = cnt + 1\n",
    "print(cnt / len(df['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07162020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
    "max_text_len = 1500\n",
    "max_summary_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8002daa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dilaporkan dua orang terluka cukup serius seme...</td>\n",
       "      <td>_START_ seekor gajah mendadak mengamuk saat pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proyek mrt sudirman lebak bulus tengah dikerja...</td>\n",
       "      <td>_START_ presiden jokowi memutuskan untuk mengh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  dilaporkan dua orang terluka cukup serius seme...   \n",
       "1  proyek mrt sudirman lebak bulus tengah dikerja...   \n",
       "\n",
       "                                             summary  \n",
       "0  _START_ seekor gajah mendadak mengamuk saat pr...  \n",
       "1  _START_ presiden jokowi memutuskan untuk mengh...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the Summaries and Text which fall below max length \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "cleaned_text = np.array(df['cleaned_text'])\n",
    "cleaned_summary= np.array(df['cleaned_summary'])\n",
    "\n",
    "short_text = []\n",
    "short_summary = []\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len:\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "post_pre = pd.DataFrame({'text': short_text,'summary': short_summary})\n",
    "\n",
    "post_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb0b01e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dilaporkan dua orang terluka cukup serius seme...</td>\n",
       "      <td>sostok _START_ seekor gajah mendadak mengamuk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>proyek mrt sudirman lebak bulus tengah dikerja...</td>\n",
       "      <td>sostok _START_ presiden jokowi memutuskan untu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  dilaporkan dua orang terluka cukup serius seme...   \n",
       "1  proyek mrt sudirman lebak bulus tengah dikerja...   \n",
       "\n",
       "                                             summary  \n",
       "0  sostok _START_ seekor gajah mendadak mengamuk ...  \n",
       "1  sostok _START_ presiden jokowi memutuskan untu...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add sostok and eostok\n",
    "\n",
    "post_pre['summary'] = post_pre['summary'].apply(lambda x: 'sostok ' + x \\\n",
    "        + ' eostok')\n",
    "\n",
    "post_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6babebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(\n",
    "    np.array(post_pre[\"text\"]),\n",
    "    np.array(post_pre[\"summary\"]),\n",
    "    test_size=0.1,\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b5a9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text to get the vocab count \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Prepare a tokenizer on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aaf1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary:  68.7322563100297\n"
     ]
    }
   ],
   "source": [
    "thresh = 5\n",
    "\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "\n",
    "for key, value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt + 1\n",
    "    if value < thresh:\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "print(\"% of rare words in vocabulary: \", (cnt / tot_cnt) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dbf2b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 52316\n"
     ]
    }
   ],
   "source": [
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "x_tokenizer = Tokenizer(num_words = tot_cnt - cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "# Pad zero upto maximum length\n",
    "x_tr = pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "x_voc = x_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "664514d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 69.61887477313975\n",
      "Size of vocabulary in Y = 10045\n"
     ]
    }
   ],
   "source": [
    "# Prepare a tokenizer on testing data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "thresh = 5\n",
    "\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "\n",
    "for key, value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt + 1\n",
    "    if value < thresh:\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt / tot_cnt) * 100)\n",
    "\n",
    "# Prepare a tokenizer, again -- by not considering the rare words\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "# Convert text sequences to integer sequences \n",
    "y_tr_seq = y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "# Pad zero upto maximum length\n",
    "y_tr = pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "# Size of vocabulary (+1 for padding token)\n",
    "y_voc = y_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "135c8e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty Summaries, .i.e, which only have 'START' and 'END' tokens\n",
    "ind = []\n",
    "\n",
    "for i in range(len(y_tr)):\n",
    "    cnt = 0\n",
    "    for j in y_tr[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt + 1\n",
    "    if cnt == 2:\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr = np.delete(y_tr, ind, axis=0)\n",
    "x_tr = np.delete(x_tr, ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bdd4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty Summaries, .i.e, which only have 'START' and 'END' tokens\n",
    "ind = []\n",
    "for i in range(len(y_val)):\n",
    "    cnt = 0\n",
    "    for j in y_val[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt + 1\n",
    "    if cnt == 2:\n",
    "        ind.append(i)\n",
    "\n",
    "y_val = np.delete(y_val, ind, axis=0)\n",
    "x_val = np.delete(x_val, ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cfe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0d983e7",
   "metadata": {},
   "source": [
    "## Model Encode Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5d1403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, \\\n",
    "    Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec7ec402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1500)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1500, 200)    10463200    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 1500, 300),  601200      ['embedding[0][0]']              \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 1500, 300),  721200      ['lstm[0][0]']                   \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 200)    2009000     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 1500, 300),  721200      ['lstm_1[0][0]']                 \n",
      "                                 (None, 300),                                                     \n",
      "                                 (None, 300)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 300),  601200      ['embedding_1[0][0]',            \n",
      "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 10045)  3023545    ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,140,545\n",
      "Trainable params: 18,140,545\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len, ))\n",
    "\n",
    "# Embedding layer\n",
    "enc_emb = Embedding(x_voc, embedding_dim,\n",
    "                    trainable=True)(encoder_inputs)\n",
    "\n",
    "# Encoder LSTM 1\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output1, state_h1, state_c1) = encoder_lstm1(enc_emb)\n",
    "\n",
    "# Encoder LSTM 2\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_output2, state_h2, state_c2) = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# Encoder LSTM 3\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "(encoder_outputs, state_h, state_c) = encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using encoder_states as the initial state\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "\n",
    "# Embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# Decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0.2)\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = \\\n",
    "    decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "601edeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df53a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_tr, y_tr[:, :-1]],\n",
    "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
    "    epochs=50,\n",
    "    callbacks=[es],\n",
    "    batch_size=128,\n",
    "    validation_data=([x_val, y_val[:, :-1]],\n",
    "                     y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:\n",
    "                     , 1:]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84533a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
